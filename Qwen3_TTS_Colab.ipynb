{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkmaan-commits/Qwen3-TTS-Colab/blob/main/Qwen3_TTS_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "57sW-0cHjthT"
      },
      "outputs": [],
      "source": [
        "#@title Install Qwen3-TTS\n",
        "%cd /content/\n",
        "# !rm -rf /content/Qwen3-TTS-Colab\n",
        "!git clone https://github.com/NeuralFalconYT/Qwen3-TTS-Colab.git\n",
        "!git clone https://github.com/QwenLM/Qwen3-TTS.git\n",
        "%cd Qwen3-TTS\n",
        "!pip install -e .\n",
        "!pip install faster-whisper==1.1.1\n",
        "!pip install ctranslate2==4.5.0\n",
        "!pip install pysrt\n",
        "!pip install sentencex\n",
        "from IPython.display import Audio,display\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "clear_output()\n",
        "\n",
        "display(Audio(\"https://raw.githubusercontent.com/NeuralFalconYT/Useful-Function/refs/heads/main/audio/warning.mp3\", autoplay=True))\n",
        "time.sleep(6)\n",
        "clear_output()\n",
        "# time.sleep(5)\n",
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Qwen3-TTS-Colab\n",
        "!python app.py --share --debug"
      ],
      "metadata": {
        "id": "v7Y8L5EDpYNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22982c8-465b-48ac-d53a-289dc2bc749c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Qwen3-TTS-Colab\n",
            "2026-02-04 06:13:29.003926: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770185609.024028    1793 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770185609.029999    1793 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770185609.045423    1793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770185609.045455    1793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770185609.045459    1793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770185609.045462    1793 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-04 06:13:29.050032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "********\n",
            "Warning: flash-attn is not installed. Will only run the manual PyTorch version. Please install flash-attn for faster inference.\n",
            "********\n",
            " \n",
            "/bin/sh: 1: sox: not found\n",
            "WARNING:sox:SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n",
            "/content/Qwen3-TTS-Colab/app.py:354: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=theme, css=css, title=\"Qwen3-TTS Demo\") as demo:\n",
            "/content/Qwen3-TTS-Colab/app.py:354: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=theme, css=css, title=\"Qwen3-TTS Demo\") as demo:\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://9ad5b1dc63a58d2d31.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Starting transcription for: /tmp/gradio/93e007c64c4a93379c4e14d0b8b87ca75e25712c8053842d276fde78949f9bdb/ref Gerald Hüther.mp3\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 2.81MB/s]\n",
            "tokenizer.json: 0.00B [00:00, ?B/s]\n",
            "vocabulary.json: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 2.26kB [00:00, 1.00MB/s]\n",
            "vocabulary.json: 1.07MB [00:00, 26.4MB/s]\n",
            "tokenizer.json: 2.71MB [00:00, 46.6MB/s]\n",
            "model.bin: 100% 1.62G/1.62G [00:09<00:00, 175MB/s]\n",
            "Starting transcription for: /tmp/gradio/93e007c64c4a93379c4e14d0b8b87ca75e25712c8053842d276fde78949f9bdb/ref Gerald Hüther.mp3\n",
            "⚠️ The text is too long. Breaking it into smaller pieces for TTS.\n",
            "Found 1 paragraphs\n",
            "Processing 1 chunks\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\n",
            "config.json: 4.49kB [00:00, 2.91MB/s]\n",
            "\n",
            "generation_config.json: 100% 245/245 [00:00<00:00, 2.63MB/s]\n",
            "\n",
            "preprocessor_config.json: 100% 127/127 [00:00<00:00, 783kB/s]\n",
            "\n",
            "merges.txt: 0.00B [00:00, ?B/s]\u001b[A\n",
            "\n",
            "config.json: 2.34kB [00:00, 15.3MB/s]\n",
            "\n",
            "\n",
            "README.md: 57.8kB [00:00, 112MB/s]\n",
            "\n",
            "\n",
            ".gitattributes: 1.52kB [00:00, 7.58MB/s]\n",
            "merges.txt: 1.67MB [00:00, 46.1MB/s]\n",
            "\n",
            "model.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "configuration.json: 100% 76.0/76.0 [00:00<00:00, 815kB/s]\n",
            "\n",
            "\n",
            "tokenizer_config.json: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "preprocessor_config.json: 100% 234/234 [00:00<00:00, 2.19MB/s]\n",
            "tokenizer_config.json: 7.34kB [00:00, 3.45MB/s]\n",
            "\n",
            "\n",
            "vocab.json: 2.78MB [00:00, 64.0MB/s]\n",
            "\n",
            "\n",
            "speech_tokenizer/model.safetensors:   0% 0.00/682M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model.safetensors:   0% 808k/3.86G [00:00<51:58, 1.24MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   1% 7.34M/682M [00:00<01:18, 8.56MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   0% 2.24M/3.86G [00:01<46:44, 1.37MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   5% 32.9M/682M [00:01<00:34, 19.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   7% 45.3M/682M [00:02<00:24, 25.8MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:   2% 69.3M/3.86G [00:04<03:36, 17.5MB/s]\u001b[A\n",
            "model.safetensors:   4% 136M/3.86G [00:05<01:46, 35.0MB/s] \u001b[A\n",
            "model.safetensors:   5% 203M/3.86G [00:06<01:26, 42.2MB/s]\u001b[A\n",
            "model.safetensors:   7% 271M/3.86G [00:07<01:09, 51.8MB/s]\u001b[A\n",
            "model.safetensors:   9% 338M/3.86G [00:07<00:45, 77.5MB/s]\u001b[A\n",
            "model.safetensors:  10% 405M/3.86G [00:10<01:24, 40.8MB/s]\u001b[A\n",
            "model.safetensors:  12% 472M/3.86G [00:10<00:58, 57.9MB/s]\u001b[A\n",
            "model.safetensors:  14% 539M/3.86G [00:11<00:50, 65.9MB/s]\u001b[A\n",
            "model.safetensors:  16% 608M/3.86G [00:12<00:55, 58.8MB/s]\u001b[A\n",
            "model.safetensors:  17% 675M/3.86G [00:12<00:40, 77.7MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:   7% 45.3M/682M [00:13<00:24, 25.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  16% 112M/682M [00:16<01:35, 5.94MB/s] \u001b[A\u001b[A\n",
            "model.safetensors:  19% 742M/3.86G [00:16<01:19, 39.0MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  26% 179M/682M [00:16<00:42, 11.9MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  21% 809M/3.86G [00:17<01:01, 49.8MB/s]\u001b[A\n",
            "model.safetensors:  23% 876M/3.86G [00:17<00:44, 66.8MB/s]\u001b[A\n",
            "model.safetensors:  24% 943M/3.86G [00:17<00:32, 89.3MB/s]\u001b[A\n",
            "model.safetensors:  26% 1.01G/3.86G [00:17<00:24, 118MB/s]\u001b[A\n",
            "model.safetensors:  28% 1.08G/3.86G [00:17<00:18, 150MB/s]\u001b[A\n",
            "model.safetensors:  30% 1.14G/3.86G [00:18<00:20, 132MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  41% 280M/682M [00:18<00:19, 20.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  31% 1.21G/3.86G [00:18<00:19, 139MB/s]\u001b[A\n",
            "model.safetensors:  33% 1.28G/3.86G [00:19<00:16, 153MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  51% 347M/682M [00:19<00:12, 26.5MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  35% 1.34G/3.86G [00:19<00:16, 150MB/s]\u001b[A\n",
            "model.safetensors:  37% 1.41G/3.86G [00:20<00:15, 161MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  61% 414M/682M [00:20<00:07, 34.0MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  38% 1.48G/3.86G [00:20<00:16, 142MB/s]\u001b[A\n",
            "model.safetensors:  40% 1.55G/3.86G [00:20<00:13, 167MB/s]\u001b[A\n",
            "model.safetensors:  42% 1.61G/3.86G [00:21<00:10, 205MB/s]\u001b[A\n",
            "model.safetensors:  44% 1.68G/3.86G [00:21<00:10, 204MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  71% 481M/682M [00:21<00:05, 38.2MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  45% 1.75G/3.86G [00:21<00:12, 175MB/s]\u001b[A\n",
            "model.safetensors:  47% 1.81G/3.86G [00:22<00:10, 189MB/s]\u001b[A\n",
            "model.safetensors:  49% 1.88G/3.86G [00:22<00:10, 184MB/s]\u001b[A\n",
            "model.safetensors:  51% 1.95G/3.86G [00:22<00:09, 204MB/s]\u001b[A\n",
            "model.safetensors:  52% 2.02G/3.86G [00:23<00:08, 211MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  80% 548M/682M [00:26<00:05, 24.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  53% 2.05G/3.86G [00:26<00:42, 42.9MB/s]\u001b[A\n",
            "model.safetensors:  55% 2.12G/3.86G [00:27<00:30, 56.7MB/s]\u001b[A\n",
            "model.safetensors:  57% 2.18G/3.86G [00:27<00:21, 76.7MB/s]\u001b[A\n",
            "model.safetensors:  58% 2.25G/3.86G [00:27<00:16, 95.9MB/s]\u001b[A\n",
            "model.safetensors:  60% 2.32G/3.86G [00:28<00:13, 112MB/s] \u001b[A\n",
            "model.safetensors:  62% 2.39G/3.86G [00:32<00:41, 35.5MB/s]\u001b[A\n",
            "model.safetensors:  64% 2.45G/3.86G [00:33<00:28, 49.9MB/s]\u001b[A\n",
            "model.safetensors:  65% 2.52G/3.86G [00:39<00:55, 24.3MB/s]\u001b[A\n",
            "model.safetensors:  69% 2.65G/3.86G [00:39<00:28, 42.0MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  80% 548M/682M [00:43<00:05, 24.1MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  71% 2.72G/3.86G [00:45<00:44, 25.7MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors:  90% 615M/682M [00:45<00:07, 8.81MB/s]\u001b[A\u001b[A\n",
            "model.safetensors:  72% 2.79G/3.86G [00:45<00:32, 33.1MB/s]\u001b[A\n",
            "\n",
            "speech_tokenizer/model.safetensors: 100% 682M/682M [00:51<00:00, 13.3MB/s]\n",
            "\n",
            "model.safetensors:  74% 2.85G/3.86G [00:51<00:45, 22.0MB/s]\u001b[A\n",
            "model.safetensors:  76% 2.92G/3.86G [00:51<00:32, 28.6MB/s]\u001b[A\n",
            "model.safetensors:  77% 2.99G/3.86G [00:57<00:42, 20.5MB/s]\u001b[A\n",
            "model.safetensors:  79% 3.06G/3.86G [00:57<00:28, 28.5MB/s]\u001b[A\n",
            "model.safetensors:  81% 3.12G/3.86G [00:58<00:21, 35.0MB/s]\u001b[A\n",
            "model.safetensors:  83% 3.19G/3.86G [00:59<00:16, 39.6MB/s]\u001b[A\n",
            "model.safetensors:  84% 3.26G/3.86G [01:01<00:14, 41.3MB/s]\u001b[A\n",
            "model.safetensors:  86% 3.32G/3.86G [01:03<00:15, 35.2MB/s]\u001b[A\n",
            "model.safetensors:  88% 3.39G/3.86G [01:03<00:09, 48.1MB/s]\u001b[A\n",
            "model.safetensors:  90% 3.46G/3.86G [01:04<00:06, 62.2MB/s]\u001b[A\n",
            "model.safetensors:  91% 3.52G/3.86G [01:04<00:04, 80.0MB/s]\u001b[A\n",
            "model.safetensors:  93% 3.59G/3.86G [01:04<00:02, 101MB/s] \u001b[A\n",
            "model.safetensors:  95% 3.66G/3.86G [01:05<00:02, 94.9MB/s]\u001b[A\n",
            "model.safetensors:  97% 3.72G/3.86G [01:09<00:03, 37.4MB/s]\u001b[A\n",
            "model.safetensors:  98% 3.79G/3.86G [01:09<00:01, 52.0MB/s]\u001b[A\n",
            "model.safetensors: 100% 3.86G/3.86G [01:10<00:00, 54.8MB/s]\n",
            "Fetching 13 files: 100% 13/13 [01:10<00:00,  5.43s/it]\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "Stitching 147 audio files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this in a Colab cell to find recent .wav files:\n",
        "!ls -lth /tmp/*.wav | head -20"
      ],
      "metadata": {
        "id": "RSRCV0YBvain"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/tmp/tmpop4ntimw.wav')"
      ],
      "metadata": {
        "id": "5-E44EwevcPt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}